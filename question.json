[
  {
    "id": "0004",
    "question": "深度學習屬於 AI 哪個技術領域的分支？",
    "options": [
      {
        "id": 1,
        "text": "自然語言處理(NLP)"
      },
      {
        "id": 2,
        "text": "計算機視覺(CV)"
      },
      {
        "id": 3,
        "text": "機器學習(ML)"
      },
      {
        "id": 4,
        "text": "專家系統"
      }
    ],
    "answer": [
      3
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 3) 機器學習（ML）\n\n[詳解]  \n深度學習以多層神經網路為核心，是機器學習的方法之一，廣泛應用於 NLP、CV、語音等。\n\n[各選項解析]  \n- 1) NLP：屬應用領域，非 DL 的上位類別。  \n- 2) CV：同屬應用領域。  \n- ✅ 3) 機器學習：DL 是 ML 的子領域。  \n- 4) 專家系統：以規則／知識庫與推理器為主，脈絡不同。\n\n[補充比較]  \n方法（ML/DL） vs 應用（NLP/CV/ASR）：DL 屬於 ML 的方法族。"
  },
  {
    "id": "0005",
    "question": "讓電腦能理解、解釋與生成人類語言的 AI 分支是？",
    "options": [
      {
        "id": 1,
        "text": "計算機視覺"
      },
      {
        "id": 2,
        "text": "自然語言處理(NLP)"
      },
      {
        "id": 3,
        "text": "機器人學"
      },
      {
        "id": 4,
        "text": "知識表示與推理"
      }
    ],
    "answer": [
      2
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 2) 自然語言處理（NLP）\n\n[詳解]  \n涵蓋斷詞、語法分析、語意理解、機器翻譯、對話、文本生成等任務。\n\n[各選項解析]  \n- 1) 計算機視覺：處理影像與影片。  \n- ✅ 2) NLP：處理與生成人類語言的核心領域。  \n- 3) 機器人學：聚焦感測、規劃、控制與人機互動。  \n- 4) 知識表示與推理：形式化知識並推理，常與 NLP 結合但非語言處理本體。\n\n[補充比較]  \nNLP × 知識圖譜（KRR）可提升事實一致性與可解釋性（如檢索增強生成）。"
  },
  {
    "id": "0006",
    "question": "目前多被視為仍在理論／未實現階段，目標是具備人類等級、可跨領域泛化的智慧是？",
    "options": [
      {
        "id": 1,
        "text": "弱人工智慧"
      },
      {
        "id": 2,
        "text": "專家系統"
      },
      {
        "id": 3,
        "text": "通用人工智慧(AGI)"
      },
      {
        "id": 4,
        "text": "超級人工智慧(ASI)"
      }
    ],
    "answer": [
      3
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 3) 通用人工智慧（AGI）\n\n[詳解]  \nAGI 期望像人類一般在多任務、多情境下學習、推理、適應，目前仍是研究目標。\n\n[各選項解析]  \n- 1) 弱人工智慧：亦稱狹義 AI，專精單任務，已大量實作。  \n- 2) 專家系統：規則／知識庫＋推理器，面向特定領域。  \n- ✅ 3) AGI：人類等級、可泛化的智慧目標。  \n- 4) ASI：假想更進一步，能力全面超越人類。\n\n[補充比較]  \n弱 AI（任務導向） < AGI（人類等級） < ASI（超越人類）。"
  },
  {
    "id": "0007",
    "question": "使電腦能從影像或影片中擷取資訊並理解的 AI 技術是？",
    "options": [
      {
        "id": 1,
        "text": "計算機視覺(Computer Vision)"
      },
      {
        "id": 2,
        "text": "自然語言處理(NLP)"
      },
      {
        "id": 3,
        "text": "語音辨識"
      },
      {
        "id": 4,
        "text": "推薦系統"
      }
    ],
    "answer": [
      1
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 1) 計算機視覺（Computer Vision）\n\n[詳解]  \n關注影像／影片的理解：目標偵測、語義分割、人臉辨識、姿態估計、追蹤等。\n\n[各選項解析]  \n- ✅ 1) 計算機視覺：專責影像與影片理解。  \n- 2) NLP：文本／語言處理。  \n- 3) 語音辨識：把語音訊號轉成文字。  \n- 4) 推薦系統：依偏好與相似度做個人化推薦。\n\n[補充比較]  \nCV、NLP、ASR 常於多模態系統整合（自駕、影音檢索、AR 等）。"
  },
  {
    "id": "0008",
    "question": "哪個子領域讓系統能在沒有明確指令下，從經驗（資料）中自動學習？",
    "options": [
      {
        "id": 1,
        "text": "規則引擎"
      },
      {
        "id": 2,
        "text": "符號計算"
      },
      {
        "id": 3,
        "text": "機器學習(Machine Learning)"
      },
      {
        "id": 4,
        "text": "模糊邏輯"
      }
    ],
    "answer": [
      3
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 3) 機器學習（Machine Learning）\n\n[詳解]  \n透過資料估計模型參數，從樣本中歸納規律（監督、非監督、半監督、強化學習等）。\n\n[各選項解析]  \n- 1) 規則引擎：人寫 if–then 規則，無資料驅動學習。  \n- 2) 符號計算：以符號與邏輯運算／推理為主。  \n- ✅ 3) 機器學習：資料驅動的自動學習方法族。  \n- 4) 模糊邏輯：處理不確定性的推理框架，非以資料自動學習為主。\n\n[補充比較]  \nNeuro-Symbolic：將 ML 與符號推理結合，兼顧泛化與可解釋性。"
  },
  {
    "id": "0009",
    "question": "下列哪一項「不是」目前狹義 AI 的典型應用？",
    "options": [
      {
        "id": 1,
        "text": "手機人臉解鎖"
      },
      {
        "id": 2,
        "text": "電商商品推薦"
      },
      {
        "id": 3,
        "text": "擁有自我意識的機器人"
      },
      {
        "id": 4,
        "text": "自動駕駛輔助系統"
      }
    ],
    "answer": [
      3
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 3) 擁有自我意識的機器人\n\n[詳解]  \n「自我意識」涉及心智與意識問題，屬 AGI/ASI 甚至哲學層級，目前沒有實務落地。\n\n[各選項解析]  \n- 1) 手機人臉解鎖：CV＋DL 的成熟應用。  \n- 2) 電商商品推薦：推薦系統的典型場景。  \n- ✅ 3) 擁有自我意識的機器人：非現實應用，不屬狹義 AI。  \n- 4) 自動駕駛輔助系統：多模型整合（感知、預測、規劃控制），屬狹義 AI。\n\n[補充比較]  \n狹義 AI 常見：辨識、預測、推薦、控制；「自我意識」不在其範疇。"
  },
  {
    "id": "0010",
    "question": "根據 AI Act，誰應該對 AI 系統行為負責任？",
    "options": [
      {
        "id": 1,
        "text": "使用者"
      },
      {
        "id": 2,
        "text": "開發者"
      },
      {
        "id": 3,
        "text": "系統本身"
      },
      {
        "id": 4,
        "text": "政府"
      }
    ],
    "answer": [
      2
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 2) 開發者\n\n[詳解]  \nAI Act 的合規主體以「提供者/開發者（provider）」為核心，需確保系統在上市前後皆符合安全、資料治理、風險管理與人類監督等義務。部署者（使用者）亦有義務，但法規要求的主責多落在提供者。\n\n[各選項解析]  \n- 1) 使用者：部署者有責（如依使用說明、監督與記錄），但非主要合規主體。  \n- ✅ 2) 開發者：主要合規與產品責任落點。  \n- 3) 系統本身：法律責任無法歸於機器。  \n- 4) 政府：負責監管與執法，不是個別系統的行為責任主體。  \n\n[補充比較]  \n提供者（主要合規） vs 部署者（依說明、監督、使用紀錄）；監管機關負責執法與抽查。"
  },
  {
    "id": "0011",
    "question": "什麼是負責任 AI 的核心原則？",
    "options": [
      {
        "id": 1,
        "text": "確保安全、可解釋與公平性"
      },
      {
        "id": 2,
        "text": "只關注技術效率"
      },
      {
        "id": 3,
        "text": "避免所有監管"
      },
      {
        "id": 4,
        "text": "促進市場壟斷"
      }
    ],
    "answer": [
      1
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 1) 確保安全、可解釋與公平性\n\n[詳解]  \n負責任 AI 強調安全、透明/可解釋、公平/去偏、隱私保護、問責與人類監督等。\n\n[各選項解析]  \n- ✅ 1) 符合主流治理原則。  \n- 2) 只看效率會忽視風險與權益。  \n- 3) 「零監管」與負責任治理相反。  \n- 4) 壟斷違反公平與競爭原則。  \n\n[補充比較]  \n常見原則：安全性、透明性、問責、隱私、去偏、公平、人類在迴路。"
  },
  {
    "id": "0012",
    "question": "負責任 AI 的關鍵原則之一是？",
    "options": [
      {
        "id": 1,
        "text": "透明性"
      },
      {
        "id": 2,
        "text": "壟斷市場"
      },
      {
        "id": 3,
        "text": "只供企業內部使用"
      },
      {
        "id": 4,
        "text": "無須考慮公平性"
      }
    ],
    "answer": [
      1
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 1) 透明性\n\n[詳解]  \n透明性（含可追溯/可解釋）讓外部可理解系統運作與限制，是問責的前提。\n\n[各選項解析]  \n- ✅ 1) 關鍵治理原則。  \n- 2) 壟斷與負責任 AI 背道而馳。  \n- 3) 使用場域不等於治理原則。  \n- 4) 公平性是核心關切，不可忽視。"
  },
  {
    "id": "0013",
    "question": "歐盟《人工智慧法案》採用的核心監管模式是？",
    "options": [
      {
        "id": 1,
        "text": "基於風險(Risk-Based Approach)"
      },
      {
        "id": 2,
        "text": "基於技術(Technology-Based Approach)"
      },
      {
        "id": 3,
        "text": "全面禁止(Total Prohibition)"
      },
      {
        "id": 4,
        "text": "自願遵守(Voluntary Compliance)"
      }
    ],
    "answer": [
      1
    ],
    "explanation": "<summary>答案與解析</summary>\n\n[正確答案] ✅ 1) 基於風險（Risk-Based Approach）\n\n[詳解]  \nAI Act 依風險等級分配義務強度：風險越高、合規要求越嚴。\n\n[各選項解析]  \n- ✅ 1) 正解：以風險分級為核心。  \n- 2) 不是鎖某技術；看用途與風險。  \n- 3) 僅「不可接受風險」才禁止。  \n- 4) 不是純自願，有法律強制力。  \n\n[補充比較]  \n四等級：不可接受／高風險／有限風險／最低或無風險。"
  }
]