### 演算法

| 演算法                           | 簡介                                                                                  | 適合的任務類型                           | 常見應用範例                                   |
| -------------------------------- | ------------------------------------------------------------------------------------- | ---------------------------------------- | ---------------------------------------------- |
| **決策樹 (Decision Tree)**       | 以類似「20 問」的方式逐步根據特徵劃分資料，形成樹狀結構，節點為條件，葉節點為預測結果 | 分類 (Classification)、回歸 (Regression) | 信用風險評估、醫療診斷、銷售預測               |
| **支援向量機 (SVM)**             | 利用超平面（Hyperplane）分隔資料，使兩類之間的間隔最大化；可用於線性或非線性分類      | 分類、回歸                               | 手寫數字辨識、垃圾郵件過濾、圖片分類           |
| **回歸 (Regression)**            | 建立數學模型來預測連續數值，輸入特徵與輸出值之間為數量關係                            | 迴歸分析（連續值預測）                   | 房價預測、銷售量預測、氣溫預測                 |
| **聚類 (Clustering)**            | 將資料分組，使同組內的資料相似度高、不同組間差異大；無監督學習方法                    | 分群 (Unsupervised Learning)             | 客戶分群、影像分割、社群網路分析               |
| **關聯規則 (Association Rule)**  | 從大量交易資料中找出項目間的關聯性，通常用於找出「X 發生時 Y 也可能發生」             | 關聯分析                                 | 購物籃分析（Market Basket Analysis）、產品推薦 |
| **異常偵測 (Anomaly Detection)** | 找出與大部分資料分布差異很大的資料點；可用統計或機器學習方法                          | 異常/偵錯                                | 金融詐欺偵測、設備故障預警、網路入侵偵測       |

---

### 支援向量機（Support Vector Machine, SVM）
是一種**監督式學習演算法**，主要用於**分類**（Classification），也可以延伸用於**回歸**（Regression，稱為 SVR）。

我用一個簡單的比喻來說：

* 假設你有兩種不同顏色的豆子（紅色、藍色）散落在桌上，你要畫一條直線把它們分成左右兩邊。
* SVM 的目標不只是畫一條「能分開」的線，而是要畫出一條**離兩邊豆子都最遠的線**，讓分類的「安全距離」最大化。
* 這條線叫 **超平面（Hyperplane）**，離它最近的豆子叫 **支援向量（Support Vectors）**，因為它們的位置決定了分隔線的位置。

* SVM 會尋找可以讓分類邊界與最近資料點距離最大的分隔線。


#### **優點**

* 適合高維度特徵（如文字分類、影像分類）。
* 對於小樣本資料集效果好。
* 理論基礎完備，有數學保證泛化能力。

#### **缺點**

* 訓練時間在大數據時可能很慢。
* 核函數選擇與參數調整需要經驗。
* 對於雜訊和重疊資料較敏感。

---

| 指標      | 中文名稱        | 定義（不含公式）                     | 生活比喻                                                            | 適用情境                               | 適用狀況說明                                                   |
| --------- | --------------- | ------------------------------------ | ------------------------------------------------------------------- | -------------------------------------- | -------------------------------------------------------------- |
| Accuracy  | 準確率          | 所有預測中，有多少比例是正確的       | 打靶時，命中紅心或靶心外圈的比例                                    | 類別比例均衡、錯誤成本差不多           | 適合資料集中各類比例接近，錯誤成本相似，例如影像辨識中辨別貓狗 |
| Precision | 精確率          | 預測為正類的案例中，有多少是真的正類 | 射中的「敵人」裡，有多少是真的敵人（沒有誤殺路人）                  | 假陽性成本高                           | 適合不希望誤報的情況，例如垃圾郵件過濾、判斷是否要逮捕嫌疑人   |
| Recall    | 召回率 / 靈敏度 | 真正的正類中，有多少被正確找出來     | 戰場上所有敵人中，有多少被打到（沒有漏掉）                          | 假陰性成本高                           | 適合不希望漏掉的情況，例如癌症篩檢、安全漏洞偵測               |
| F1-score  | F1 分數         | Precision 與 Recall 的平衡綜合指標   | 既要命中率高（Precision），又要能打到大部分敵人（Recall）的綜合成績 | Precision 與 Recall 都重要、類別不平衡 | 適合需要同時兼顧精確率與召回率的任務，例如搜尋引擎、問答系統   |

---

| 面向                   | 分類型                                                                            | 常見演算法 / 模型                                                  | 常用評估方式                                                                                                                               | 常見應用                             |
| ---------------------- | --------------------------------------------------------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------ |
| **監督式學習 (SL)**    | <span style="background-color:#CFE2FF">**分類 (Classification)**</span>           | - 決策樹 (Decision Tree)<br>- K 最近鄰 (KNN)<br>- 支援向量機 (SVM) | - 準確率 (Accuracy)：整體預測對的比例<br>- 精確率 (Precision)：預測為正類中，正確的比例<br>- 召回率 (Recall)：所有正類中，被正確找出的比例 | - 垃圾郵件判斷<br>- 身份識別         |
|                        | <span style="background-color:#FFF3CD">**回歸 (Regression)**</span>               | - 線性回歸 (Linear Regression)<br>- 隨機森林回歸                   | - 平均平方誤差 (MSE)：預測值與真實值差距的平方平均<br>- R²：模型解釋資料變異的能力                                                         | - 房價預測<br>- 銷售量預估           |
| **非監督式學習 (USL)** | <span style="background-color:#FFE5B4">**分群 (Clustering)**</span>               | - K-means                                                          | - 輪廓係數 (Silhouette Score)：群內緊密度與群間分離度                                                                                      | - 客戶群分類                         |
|                        | <span style="background-color:#D1E7DD">**降維 (Dimensionality Reduction)**</span> | - 隨機式分群<br>- 主成分分析 (PCA)                                 | - 聚類可視化分析：降維後檢查數據分佈                                                                                                       | - 市場區隔分析<br>- 圖像壓縮         |
| **強化學習 (RL)**      | <span style="background-color:#F8D7DA">**策略學習**</span>                        | - Q-learning                                                       | - 累積獎勵 (Cumulative Reward)：整體任務中累積的分數或獎勵                                                                                 | - AI 打遊戲（如 AlphaGo）            |
|                        | <span style="background-color:#F8D7DA">**決策優化**</span>                        | - 深度強化學習 (DQN)                                               | - 策略收斂速度：多快找到最佳策略                                                                                                           | - 自動駕駛<br>- 機器人動作學習       |
| **多用途演算法**       | <span style="background-color:#E2E3E5">可同時用於分類 / 回歸 / 分群</span>        | - 隨機森林 (RF)<br>- 神經網路 (ANN)<br>- 支援向量機 (SVM)          | 依不同任務選擇對應的評估方式                                                                                                               | - 醫療、金融、零售、工業等多領域應用 |

---

| 名稱                                                         | 英文縮寫 / 全名                    | 所屬類型                            | 簡單定義                                      | 生活化例子                               |
| ------------------------------------------------------------ | ---------------------------------- | ----------------------------------- | --------------------------------------------- | ---------------------------------------- |
| <span style="background-color:#CFE2FF">K 最近鄰</span>       | KNN (K-Nearest Neighbors)          | 監督式學習（分類 / 回歸）           | 判斷新資料時，看它最近的 K 個鄰居屬於哪一類   | 判斷水果種類，看它最像的 K 個水果是什麼  |
| <span style="background-color:#FFE5B4">輪廓係數</span>       | Silhouette Score                   | 非監督式學習（分群評估）            | 衡量分群效果好壞，介於 -1 \~ 1<br>越接近 1：同一群內的點很接近，和其他群的距離很遠 → 分群效果好<br>越接近 0：群與群之間分不清楚<br>小於 0：可能分錯群                | 分桌吃飯，同桌人熟、不同桌差異大就是高分 |
| <span style="background-color:#D1E7DD">主成分分析</span>     | PCA (Principal Component Analysis) | 非監督式學習（降維）                | 壓縮資料維度，保留主要資訊、去掉噪音          | 將 100 個特徵濃縮成 2\~3 個主要指標      |
| <span style="background-color:#FFE5B4">聚類可視化分析</span> | Clustering Visualization           | 非監督式學習（分群結果分析）        | 將分群結果畫成圖表，方便理解                  | 用不同顏色顯示客戶分群分佈               |
| <span style="background-color:#F8D7DA">Q-learning</span>     | Q-learning                         | 強化學習                            | 用嘗試錯誤學最佳動作，最大化累積獎勵，Q 其實是指 "Quality"（品質），Q-learning 的目的就是學到：在每個狀態下，選擇 Q 值最高的動作          | 機器人學走路，走對加分、撞牆扣分         |
| <span style="background-color:#F8D7DA">AlphaGo</span>        | AlphaGo                            | 強化學習（深度學習 + 蒙地卡羅搜索） | Google DeepMind 的圍棋 AI，自我對弈訓練       | 2016 年打敗世界冠軍李世乭                |
| <span style="background-color:#F8D7DA">深度強化學習</span>   | DQN (Deep Q-Network)               | 強化學習                            | Q-learning + 深度神經網路，處理圖片、聲音等高維輸入 | AI 學玩 Atari 電玩，直接看畫面決定動作   |
| <span style="background-color:#F8D7DA">策略收斂速度</span>   | Policy Convergence Speed           | 強化學習評估指標                    | 多快找到穩定有效的策略                        | 兩個 AI 學開車，比誰更快穩定不撞車       |
| <span style="background-color:#E2E3E5">隨機森林</span>       | RF (Random Forest)                 | 監督式學習（分類 / 回歸）           | 多棵決策樹投票或取平均，避免過擬合            | 多位醫生診斷，採大多數意見               |
| <span style="background-color:#E2E3E5">神經網路</span>       | ANN (Artificial Neural Network)    | 通用（分類 / 回歸 / 強化學習）      | 模仿人腦神經元連結的數學模型，能自動學習輸入與輸出之間的關係。                  | 貓狗辨識、Siri 語音辨識、Google 翻譯     |

---

#### **神經網路為什麼能自動學習**

1. **神經元（Neuron）** → 接收輸入 → 乘權重 → 加總 → 激活函數 → 輸出
2. **多層結構** → 疊加多層非線性函數 → 學複雜模式（可近似任何函數）
3. **學習流程**

   * 初始化權重（隨機）
   * 前向傳播（輸入 → 計算輸出）
   * 計算誤差（輸出 vs 答案）
   * 反向傳播（算每個權重對誤差的影響）
   * 梯度下降（調整權重，減少誤差）
   * 重複訓練直到收斂
4. **為什麼有效**

   * 每層提取不同層次特徵（低層 → 中層 → 高層）
   * 權重 = 模型記憶
   * 不需人工設公式，資料本身驅動學習
5. **生活比喻**

   * 調飲料配方 → 權重 = 糖/冰/茶比例 → 顧客評分 = 誤差 → 調比例 → 變好喝

---

| 縮寫           | 全名                             | 中文名稱       | 特點                        | 常見用途             | **速記**           |
| -------------- | -------------------------------- | -------------- | --------------------------- | -------------------- | ------------------ |
| **AE**         | Autoencoder                      | 自編碼器       | 壓縮 → 還原，學資料關鍵特徵 | 降維、去雜訊、壓縮   | 原始 → 壓縮 → 還原 |
| **DAE**        | Denoising Autoencoder            | 去雜訊自編碼器 | 加雜訊再還原乾淨版本        | 影像去雜訊、訊號修復 | 還原乾淨資料       |
| **SAE**        | Sparse Autoencoder               | 稀疏自編碼器   | 強制隱藏層少量激活          | 特徵提取             | 用更少特徵表達     |
| **VAE**        | Variational Autoencoder          | 變分自編碼器   | 學特徵分佈，可生成新資料    | 生成圖片、數據增強   | 生成新資料         |
| **CAE**        | Convolutional Autoencoder        | 卷積自編碼器   | 卷積層處理影像特徵          | 影像壓縮、去雜訊     | 專門處理影像       |
| **Seq2Seq AE** | Sequence-to-Sequence Autoencoder | 序列自編碼器   | RNN/LSTM 處理序列           | 語音、機器翻譯預訓練 | 處理時間序列       |


---

| 縮寫            | 全名                           | 中文名稱       | 特點                                        | 常見用途                   | **速記**     |
| --------------- | ------------------------------ | -------------- | ------------------------------------------- | -------------------------- | ------------ |
| **ANN**         | Artificial Neural Network      | 人工神經網路   | 最基本的神經網路，輸入層 → 隱藏層 → 輸出層  | 分類、回歸                 | 基本款       |
| **MLP**         | Multi-Layer Perceptron         | 多層感知器     | 多層全連接神經元，可處理非線性問題          | 圖片分類、語音辨識         | 多層全連接   |
| **CNN**         | Convolutional Neural Network   | 卷積神經網路   | 卷積層提取局部特徵，適合處理圖像            | 影像辨識、物體偵測         | 看圖高手     |
| **RNN**         | Recurrent Neural Network       | 循環神經網路   | 處理序列資料，會記憶前一步資訊              | 語音辨識、文字生成         | 記憶型       |
| **LSTM**        | Long Short-Term Memory         | 長短期記憶網路 | 特殊 RNN，能記長期依賴，避免梯度消失        | 機器翻譯、對話系統         | 長期記憶     |
| **GRU**         | Gated Recurrent Unit           | 閘控循環單元   | LSTM 簡化版，計算更快                       | 語音、文字處理             | 輕量記憶     |
| **GAN**         | Generative Adversarial Network | 生成對抗網路   | 生成器與判別器互相對抗產生資料              | AI 繪圖、影像生成          | 對戰生圖     |
| **AE**          | Autoencoder                    | 自編碼器       | 壓縮 → 還原資料，學特徵                     | 降維、去雜訊               | 壓縮還原     |
| **VAE**         | Variational Autoencoder        | 變分自編碼器   | 學資料分佈，可生成新資料                    | 生成圖片、數據增強         | 生成新資料 |
| **DQN**         | Deep Q-Network                 | 深度 Q 網路    | 強化學習 + 深度學習                         | 遊戲 AI、自駕車            | 玩遊戲學策略 |
| **Transformer** | Transformer                    | 變壓器網路     | 基於注意力機制（Attention），擅長處理長序列 | ChatGPT、翻譯              | 長文高手     |
| **GNN**         | Graph Neural Network           | 圖神經網路     | 處理圖結構資料（節點 + 邊）                 | 社交網路分析、化學分子分析 | 圖形專家     |

---

#### **Transformer**

1. **是什麼**

   * 一種基於 **注意力機制（Attention）** 的神經網路架構
   * 專門用來處理序列資料（文字、語音等）
   * 不用像 RNN 一樣逐步讀取，而是一次看整段 → **可並行運算，速度快**

2. **核心概念**

   * **Self-Attention（自注意力）**：讓每個詞都能根據整句話的所有詞來理解上下文
   * **位置編碼（Positional Encoding）**：因為一次讀整段，必須加上位置資訊
   * **編碼器（Encoder）**：理解輸入
   * **解碼器（Decoder）**：生成輸出（翻譯、回覆等）

3. **為什麼重要**

   * 可同時處理長距離依賴（long-term dependencies）
   * 訓練速度比 RNN/LSTM 快很多
   * 是 GPT、BERT、ChatGPT 這些大型語言模型的基礎

4. **常見應用**

   * 機器翻譯（Google Translate）
   * 聊天機器人（ChatGPT）
   * 文件摘要、情感分析
   * 文字生成、程式碼生成

5. **速記**

   > **Transformer = Attention + 並行 + 長文高手**

---

| 演算法                                 | 中文名稱     | 特點                                                         | 常見用途               | 速記           |
| -------------------------------------- | ------------ | ------------------------------------------------------------ | ---------------------- | -------------- |
| **Logistic Regression**                | 邏輯回歸     | **線性加權 + Sigmoid 函數（把分數壓到 0\~1 機率）** → 再分類 | 垃圾郵件判斷、疾病預測 | 算機率再分類   |
| **Linear Discriminant Analysis (LDA)** | 線性判別分析 | 找到最佳分隔線，最大化類間距、最小化類內距                   | 臉部辨識、模式識別     | 找最好的分界線 |
| **Naive Bayes**                        | 樸素貝葉斯   | 用條件機率做分類，假設特徵獨立                               | 文字分類、垃圾郵件過濾 | 用機率投票     |
| **Decision Tree**                      | 決策樹       | 用條件分支做分類，直觀易解釋                                 | 客戶分類、風險評估     | 像 20 問遊戲   |
| **Support Vector Machine (SVM)**       | 支援向量機   | 找到最大間隔的分隔超平面                                     | 影像分類、手寫字辨識   | 分界要離得最開 |
| **K-Nearest Neighbors (KNN)**          | K 最近鄰     | 看最近的 K 個鄰居屬於哪一類                                  | 推薦系統、分類         | 跟鄰居投票     |

---

| 模型                     | 中文名稱       | 核心原理                                           | 常見應用                                       | 速記         |
| ------------------------ | -------------- | -------------------------------------------------- | ---------------------------------------------- | ------------ |
| **Diffusion Model**      | 擴散模型       | 從資料逐步加雜訊（前向）→ 學去雜訊（反向）還原資料 | 文生圖（Stable Diffusion）、影像修補、影片生成 | 擦掉雜訊還原圖 |
| **GAN**                  | 生成對抗網路   | 生成器 vs 判別器對抗學習，生成器騙過判別器         | AI 繪圖、影像生成、Deepfake                    | 對戰生圖     |
| **VAE**                  | 變分自編碼器   | 學資料分佈，從隨機向量生成樣本                     | 圖像生成、數據增強                             | 學分佈隨機生圖 |
| **Flow-based Model**     | 流式模型       | 可逆變換學資料分佈，生成時直接反推                 | 高質量圖片生成、密度估計                       | 反推變回圖     |
| **Autoregressive Model** | 自回歸生成模型 | 依序生成下一個元素（像 GPT 生成文字）              | 文字生成、音樂生成                             | 接龍生資料   |

---

| 任務類型                               | 常用評估指標                                 | 一句話速記                       |
| -------------------------------------- | -------------------------------------------- | -------------------------------- |
| **分類（Classification）**             | **Accuracy（準確率）**                       | 預測正確的比例                   |
|                                        | **Precision（精確率）**                      | 預測為正中有多少是真的正         |
|                                        | **Recall（召回率 / 靈敏度）**                | 真正的正中有多少被找出           |
|                                        | **F1-score（F1 分數）**                      | Precision 與 Recall 的平衡       |
|                                        | **ROC-AUC（ROC 曲線下面積）**                | 分類能力整體表現                 |
|                                        | **Log Loss（對數損失）**                     | 考慮預測機率準不準               |
| **回歸（Regression）**                 | **MSE（均方誤差）**                          | 誤差平方平均，懲罰大誤差         |
|                                        | **RMSE（均方根誤差）**                       | 誤差平方根，單位與原數據一致     |
|                                        | **MAE（平均絕對誤差）**                      | 誤差絕對值平均，平等對待所有誤差 |
|                                        | **R²（決定係數）**                           | 模型解釋變異的比例               |
| **分群（Clustering）**                 | **Silhouette Score（輪廓係數）**             | 群內緊密、群間分離度             |
|                                        | **DBI（Davies–Bouldin Index）**              | 群之間分離與相似度               |
|                                        | **ARI（Adjusted Rand Index）**               | 與真實分類的相似度               |
| **降維（Dimensionality Reduction）**   | **Explained Variance Ratio（解釋變異比例）** | 主成分解釋的資訊量               |
|                                        | **Reconstruction Error（重建誤差）**         | 壓縮後還原的差異                 |
| **生成（Generative Models）**          | **FID（Fréchet Inception Distance）**        | 生成影像與真實影像的距離         |
|                                        | **IS（Inception Score）**                    | 生成影像的質量與多樣性           |
|                                        | **CLIP Score（CLIP 分數）**                  | 圖像與文字的匹配度               |
| **強化學習（Reinforcement Learning）** | **Cumulative Reward（累積獎勵）**            | 任務中的總得分                   |
|                                        | **Win Rate（勝率）**                         | 對戰任務贏的比例                 |
|                                        | **Convergence Speed（收斂速度）**            | 學到穩定策略的快慢               |

---

