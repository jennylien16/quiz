### 演算法

| 演算法                           | 簡介                                                                                  | 適合的任務類型                           | 常見應用範例                                   |
| -------------------------------- | ------------------------------------------------------------------------------------- | ---------------------------------------- | ---------------------------------------------- |
| **決策樹 (Decision Tree)**       | 以類似「20 問」的方式逐步根據特徵劃分資料，形成樹狀結構，節點為條件，葉節點為預測結果 | 分類 (Classification)、回歸 (Regression) | 信用風險評估、醫療診斷、銷售預測               |
| **支援向量機 (SVM)**             | 利用超平面（Hyperplane）分隔資料，使兩類之間的間隔最大化；可用於線性或非線性分類      | 分類、回歸                               | 手寫數字辨識、垃圾郵件過濾、圖片分類           |
| **回歸 (Regression)**            | 建立數學模型來預測連續數值，輸入特徵與輸出值之間為數量關係                            | 迴歸分析（連續值預測）                   | 房價預測、銷售量預測、氣溫預測                 |
| **聚類 (Clustering)**            | 將資料分組，使同組內的資料相似度高、不同組間差異大；無監督學習方法                    | 分群 (Unsupervised Learning)             | 客戶分群、影像分割、社群網路分析               |
| **關聯規則 (Association Rule)**  | 從大量交易資料中找出項目間的關聯性，通常用於找出「X 發生時 Y 也可能發生」             | 關聯分析                                 | 購物籃分析（Market Basket Analysis）、產品推薦 |
| **異常偵測 (Anomaly Detection)** | 找出與大部分資料分布差異很大的資料點；可用統計或機器學習方法                          | 異常/偵錯                                | 金融詐欺偵測、設備故障預警、網路入侵偵測       |

---

### 支援向量機（Support Vector Machine, SVM）
是一種**監督式學習演算法**，主要用於**分類**（Classification），也可以延伸用於**回歸**（Regression，稱為 SVR）。

我用一個簡單的比喻來說：

* 假設你有兩種不同顏色的豆子（紅色、藍色）散落在桌上，你要畫一條直線把它們分成左右兩邊。
* SVM 的目標不只是畫一條「能分開」的線，而是要畫出一條**離兩邊豆子都最遠的線**，讓分類的「安全距離」最大化。
* 這條線叫 **超平面（Hyperplane）**，離它最近的豆子叫 **支援向量（Support Vectors）**，因為它們的位置決定了分隔線的位置。

* SVM 會尋找可以讓分類邊界與最近資料點距離最大的分隔線。


#### **優點**

* 適合高維度特徵（如文字分類、影像分類）。
* 對於小樣本資料集效果好。
* 理論基礎完備，有數學保證泛化能力。

#### **缺點**

* 訓練時間在大數據時可能很慢。
* 核函數選擇與參數調整需要經驗。
* 對於雜訊和重疊資料較敏感。

---

| 指標      | 中文名稱        | 定義（不含公式）                     | 生活比喻                                                            | 適用情境                               | 適用狀況說明                                                   |
| --------- | --------------- | ------------------------------------ | ------------------------------------------------------------------- | -------------------------------------- | -------------------------------------------------------------- |
| Accuracy  | 準確率          | 所有預測中，有多少比例是正確的       | 打靶時，命中紅心或靶心外圈的比例的                                    | 類別比例均衡、錯誤成本差不多           | 適合資料集中各類比例接近，錯誤成本相似，例如影像辨識中辨別貓狗 |
| Precision | 精確率          | 預測為正類的案例中，有多少是真的正類；<br><span style="background-color:#F8D7DA">**說中的有幾個是真（不亂說）**</span> | 射中的「敵人」裡，有多少是真的敵人（沒有誤殺路人）                  | 假陽性成本高                           | 適合不希望誤報的情況，例如垃圾郵件過濾、判斷是否要逮捕嫌疑人   |
| Recall    | 召回率 / 靈敏度 | 真正的正類中，有多少被正確找出來；<br><span style="background-color:#F8D7DA">**真的有幾個被說（不漏）**</span>     | 戰場上所有敵人中，有多少被打到（沒有漏掉）中                          | 假陰性成本高                           | 適合不希望漏掉的情況，例如癌症篩檢、安全漏洞偵測               |
| F1-score  | F1 分數         | Precision 與 Recall 的平衡綜合指標   | 既要命中率高（Precision），又要能打到大部分敵人（Recall）的綜合成績 | Precision 與 Recall 都重要、類別不平衡 | 適合需要同時兼顧精確率與召回率的任務，例如搜尋引擎、問答系統   |

---

| 面向                   | 分類型                                                                            | 常見演算法 / 模型                                                  | 常用評估方式                                                                                                                               | 常見應用                             |
| ---------------------- | --------------------------------------------------------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------ |
| **監督式學習 (SL)**    | <span style="background-color:#CFE2FF">**分類 (Classification)**</span>           | - 決策樹 (Decision Tree)<br>- K 最近鄰 (KNN)<br>- 支援向量機 (SVM) | - 準確率 (Accuracy)：整體預測對的比例<br>- 精確率 (Precision)：預測為正類中，正確的比例<br>- 召回率 (Recall)：所有正類中，被正確找出的比例 | - 垃圾郵件判斷<br>- 身份識別         |
|                        | <span style="background-color:#FFF3CD">**回歸 (Regression)**</span>               | - 線性回歸 (Linear Regression)<br>- 隨機森林回歸                   | - 平均平方誤差 (MSE)：預測值與真實值差距的平方平均<br>- R²：模型解釋資料變異的能力                                                         | - 房價預測<br>- 銷售量預估           |
| **非監督式學習 (USL)** | <span style="background-color:#FFE5B4">**分群 (Clustering)**</span>               | - K-means                                                          | - 輪廓係數 (Silhouette Score)：群內緊密度與群間分離度                                                                                      | - 客戶群分類                         |
|                        | <span style="background-color:#D1E7DD">**降維 (Dimensionality Reduction)**</span> | - 隨機式分群<br>- 主成分分析 (PCA)                                 | - 聚類可視化分析：降維後檢查數據分佈                                                                                                       | - 市場區隔分析<br>- 圖像壓縮         |
| **強化學習 (RL)**      | <span style="background-color:#F8D7DA">**策略學習**</span>                        | - Q-learning                                                       | - 累積獎勵 (Cumulative Reward)：整體任務中累積的分數或獎勵                                                                                 | - AI 打遊戲（如 AlphaGo）            |
|                        | <span style="background-color:#F8D7DA">**決策優化**</span>                        | - 深度強化學習 (DQN)                                               | - 策略收斂速度：多快找到最佳策略                                                                                                           | - 自動駕駛<br>- 機器人動作學習       |
| **多用途演算法**       | <span style="background-color:#E2E3E5">可同時用於分類 / 回歸 / 分群</span>        | - 隨機森林 (RF)<br>- 神經網路 (ANN)<br>- 支援向量機 (SVM)          | 依不同任務選擇對應的評估方式                                                                                                               | - 醫療、金融、零售、工業等多領域應用 |

---

| 名稱                                                         | 英文縮寫 / 全名                    | 所屬類型                            | 簡單定義                                      | 生活化例子                               |
| ------------------------------------------------------------ | ---------------------------------- | ----------------------------------- | --------------------------------------------- | ---------------------------------------- |
| <span style="background-color:#CFE2FF">K 最近鄰</span>       | KNN (K-Nearest Neighbors)          | 監督式學習（分類 / 回歸）           | 判斷新資料時，看它最近的 K 個鄰居屬於哪一類   | 判斷水果種類，看它最像的 K 個水果是什麼  |
| <span style="background-color:#FFE5B4">輪廓係數</span>       | Silhouette Score                   | 非監督式學習（分群評估）            | 衡量分群效果好壞，介於 -1 \~ 1<br>越接近 1：同一群內的點很接近，和其他群的距離很遠 → 分群效果好<br>越接近 0：群與群之間分不清楚<br>小於 0：可能分錯群                | 分桌吃飯，同桌人熟、不同桌差異大就是高分 |
| <span style="background-color:#D1E7DD">主成分分析</span>     | PCA (Principal Component Analysis) | 非監督式學習（降維）                | 壓縮資料維度，保留主要資訊、去掉噪音          | 將 100 個特徵濃縮成 2\~3 個主要指標      |
| <span style="background-color:#FFE5B4">聚類可視化分析</span> | Clustering Visualization           | 非監督式學習（分群結果分析）        | 將分群結果畫成圖表，方便理解                  | 用不同顏色顯示客戶分群分佈               |
| <span style="background-color:#F8D7DA">Q-learning</span>     | Q-learning                         | 強化學習                            | 用嘗試錯誤學最佳動作，最大化累積獎勵，Q 其實是指 "Quality"（品質），Q-learning 的目的就是學到：在每個狀態下，選擇 Q 值最高的動作          | 機器人學走路，走對加分、撞牆扣分         |
| <span style="background-color:#F8D7DA">AlphaGo</span>        | AlphaGo                            | 強化學習（深度學習 + 蒙地卡羅搜索） | Google DeepMind 的圍棋 AI，自我對弈訓練       | 2016 年打敗世界冠軍李世乭                |
| <span style="background-color:#F8D7DA">深度強化學習</span>   | DQN (Deep Q-Network)               | 強化學習                            | Q-learning + 深度神經網路，處理圖片、聲音等高維輸入 | AI 學玩 Atari 電玩，直接看畫面決定動作   |
| <span style="background-color:#F8D7DA">策略收斂速度</span>   | Policy Convergence Speed           | 強化學習評估指標                    | 多快找到穩定有效的策略                        | 兩個 AI 學開車，比誰更快穩定不撞車       |
| <span style="background-color:#E2E3E5">隨機森林</span>       | RF (Random Forest)                 | 監督式學習（分類 / 回歸）           | 多棵決策樹投票或取平均，避免過擬合            | 多位醫生診斷，採大多數意見               |
| <span style="background-color:#E2E3E5">神經網路</span>       | ANN (Artificial Neural Network)    | 通用（分類 / 回歸 / 強化學習）      | 模仿人腦神經元連結的數學模型，能自動學習輸入與輸出之間的關係。                  | 貓狗辨識、Siri 語音辨識、Google 翻譯     |

---

#### **神經網路為什麼能自動學習**

1. **神經元（Neuron）** → 接收輸入 → 乘權重 → 加總 → 激活函數 → 輸出
2. **多層結構** → 疊加多層非線性函數 → 學複雜模式（可近似任何函數）
3. **學習流程**

   * 初始化權重（隨機）
   * 前向傳播（輸入 → 計算輸出）
   * 計算誤差（輸出 vs 答案）
   * 反向傳播（算每個權重對誤差的影響）
   * 梯度下降（調整權重，減少誤差）
   * 重複訓練直到收斂
4. **為什麼有效**

   * 每層提取不同層次特徵（低層 → 中層 → 高層）
   * 權重 = 模型記憶
   * 不需人工設公式，資料本身驅動學習
5. **生活比喻**

   * 調飲料配方 → 權重 = 糖/冰/茶比例 → 顧客評分 = 誤差 → 調比例 → 變好喝

---

| 縮寫           | 全名                             | 中文名稱       | 特點                        | 常見用途             | **速記**           |
| -------------- | -------------------------------- | -------------- | --------------------------- | -------------------- | ------------------ |
| **AE**         | Autoencoder                      | 自編碼器       | 壓縮 → 還原，學資料關鍵特徵 | 降維、去雜訊、壓縮   | 原始 → 壓縮 → 還原 |
| **DAE**        | Denoising Autoencoder            | 去雜訊自編碼器 | 加雜訊再還原乾淨版本        | 影像去雜訊、訊號修復 | 還原乾淨資料       |
| **SAE**        | Sparse Autoencoder               | 稀疏自編碼器   | 強制隱藏層少量激活          | 特徵提取             | 用更少特徵表達     |
| **VAE**        | Variational Autoencoder          | 變分自編碼器   | 學特徵分佈，可生成新資料    | 生成圖片、數據增強   | 生成新資料         |
| **CAE**        | Convolutional Autoencoder        | 卷積自編碼器   | 卷積層處理影像特徵          | 影像壓縮、去雜訊     | 專門處理影像       |
| **Seq2Seq AE** | Sequence-to-Sequence Autoencoder | 序列自編碼器   | RNN/LSTM 處理序列           | 語音、機器翻譯預訓練 | 處理時間序列       |


---

| 縮寫            | 全名                           | 中文名稱       | 特點                                        | 常見用途                   | **速記**     |
| --------------- | ------------------------------ | -------------- | ------------------------------------------- | -------------------------- | ------------ |
| **ANN**         | Artificial Neural Network      | 人工神經網路   | 最基本的神經網路，輸入層 → 隱藏層 → 輸出層  | 分類、回歸                 | 基本款       |
| **MLP**         | Multi-Layer Perceptron         | 多層感知器     | 多層全連接神經元，可處理非線性問題          | 圖片分類、語音辨識         | 多層全連接   |
| **CNN**         | Convolutional Neural Network   | 卷積神經網路   | 卷積層提取局部特徵，適合處理圖像            | 影像辨識、物體偵測         | 看圖高手     |
| **RNN**         | Recurrent Neural Network       | 循環神經網路   | 處理序列資料，會記憶前一步資訊              | 語音辨識、文字生成         | 記憶型       |
| **LSTM**        | Long Short-Term Memory         | 長短期記憶網路 | 特殊 RNN，能記長期依賴，避免梯度消失        | 機器翻譯、對話系統         | 長期記憶     |
| **GRU**         | Gated Recurrent Unit           | 閘控循環單元   | LSTM 簡化版，計算更快                       | 語音、文字處理             | 輕量記憶     |
| **GAN**         | Generative Adversarial Network | 生成對抗網路   | 生成器與判別器互相對抗產生資料              | AI 繪圖、影像生成          | 對戰生圖     |
| **AE**          | Autoencoder                    | 自編碼器       | 壓縮 → 還原資料，學特徵                     | 降維、去雜訊               | 壓縮還原     |
| **VAE**         | Variational Autoencoder        | 變分自編碼器   | 學資料分佈，可生成新資料                    | 生成圖片、數據增強         | 生成新資料 |
| **DQN**         | Deep Q-Network                 | 深度 Q 網路    | 強化學習 + 深度學習                         | 遊戲 AI、自駕車            | 玩遊戲學策略 |
| **Transformer** | Transformer                    | 變壓器網路     | 基於注意力機制（Attention），擅長處理長序列 | ChatGPT、翻譯              | 長文高手     |
| **GNN**         | Graph Neural Network           | 圖神經網路     | 處理圖結構資料（節點 + 邊）                 | 社交網路分析、化學分子分析 | 圖形專家     |

---

#### **Transformer**

1. **是什麼**

   * 一種基於 **注意力機制（Attention）** 的神經網路架構
   * 專門用來處理序列資料（文字、語音等）
   * 不用像 RNN 一樣逐步讀取，而是一次看整段 → **可並行運算，速度快**

2. **核心概念**

   * **Self-Attention（自注意力）**：讓每個詞都能根據整句話的所有詞來理解上下文
   * **位置編碼（Positional Encoding）**：因為一次讀整段，必須加上位置資訊
   * **編碼器（Encoder）**：理解輸入
   * **解碼器（Decoder）**：生成輸出（翻譯、回覆等）

3. **為什麼重要**

   * 可同時處理長距離依賴（long-term dependencies）
   * 訓練速度比 RNN/LSTM 快很多
   * 是 GPT、BERT、ChatGPT 這些大型語言模型的基礎

4. **常見應用**

   * 機器翻譯（Google Translate）
   * 聊天機器人（ChatGPT）
   * 文件摘要、情感分析
   * 文字生成、程式碼生成

5. **速記**

   > **Transformer = Attention + 並行 + 長文高手**

---

| 演算法                                 | 中文名稱     | 特點                                                         | 常見用途               | 速記           |
| -------------------------------------- | ------------ | ------------------------------------------------------------ | ---------------------- | -------------- |
| **Logistic Regression**                | 邏輯回歸     | **線性加權 + Sigmoid 函數（把分數壓到 0\~1 機率）** → 再分類 | 垃圾郵件判斷、疾病預測 | 算機率再分類   |
| **Linear Discriminant Analysis (LDA)** | 線性判別分析 | 找到最佳分隔線，最大化類間距、最小化類內距                   | 臉部辨識、模式識別     | 找最好的分界線 |
| **Naive Bayes**                        | 樸素貝葉斯   | 用條件機率做分類，假設特徵獨立                               | 文字分類、垃圾郵件過濾 | 用機率投票     |
| **Decision Tree**                      | 決策樹       | 用條件分支做分類，直觀易解釋                                 | 客戶分類、風險評估     | 像 20 問遊戲   |
| **Support Vector Machine (SVM)**       | 支援向量機   | 找到最大間隔的分隔超平面                                     | 影像分類、手寫字辨識   | 分界要離得最開 |
| **K-Nearest Neighbors (KNN)**          | K 最近鄰     | 看最近的 K 個鄰居屬於哪一類                                  | 推薦系統、分類         | 跟鄰居投票     |

---

| 模型                     | 中文名稱       | 核心原理                                           | 常見應用                                       | 速記         |
| ------------------------ | -------------- | -------------------------------------------------- | ---------------------------------------------- | ------------ |
| **Diffusion Model**      | 擴散模型       | 從資料逐步加雜訊（前向）→ 學去雜訊（反向）還原資料 | 文生圖（Stable Diffusion）、影像修補、影片生成 | 擦掉雜訊還原圖 |
| **GAN**                  | 生成對抗網路   | 生成器 vs 判別器對抗學習，生成器騙過判別器         | AI 繪圖、影像生成、Deepfake                    | 對戰生圖     |
| **VAE**                  | 變分自編碼器   | 學資料分佈，從隨機向量生成樣本                     | 圖像生成、數據增強                             | 學分佈隨機生圖 |
| **Flow-based Model**     | 流式模型       | 可逆變換學資料分佈，生成時直接反推                 | 高質量圖片生成、密度估計                       | 反推變回圖     |
| **Autoregressive Model** | 自回歸生成模型 | 依序生成下一個元素（像 GPT 生成文字）              | 文字生成、音樂生成                             | 接龍生資料   |

---

| 任務類型                               | 常用評估指標                                 | 一句話速記                       |
| -------------------------------------- | -------------------------------------------- | -------------------------------- |
| **分類（Classification）**             | **Accuracy（準確率）**                       | 預測正確的比例                   |
|                                        | **Precision（精確率）**                      | 預測為正中有多少是真的正         |
|                                        | **Recall（召回率 / 靈敏度）**                | 真正的正中有多少被找出           |
|                                        | **F1-score（F1 分數）**                      | Precision 與 Recall 的平衡       |
|                                        | **ROC-AUC（ROC 曲線下面積）**                | 分類能力整體表現                 |
|                                        | **Log Loss（對數損失）**                     | 考慮預測機率準不準               |
| **回歸（Regression）**                 | **MSE（均方誤差）**                          | 誤差平方平均，懲罰大誤差         |
|                                        | **RMSE（均方根誤差）**                       | 誤差平方根，單位與原數據一致     |
|                                        | **MAE（平均絕對誤差）**                      | 誤差絕對值平均，平等對待所有誤差 |
|                                        | **R²（決定係數）**                           | 模型解釋變異的比例               |
| **分群（Clustering）**                 | **Silhouette Score（輪廓係數）**             | 群內緊密、群間分離度             |
|                                        | **DBI（Davies–Bouldin Index）**              | 群之間分離與相似度               |
|                                        | **ARI（Adjusted Rand Index）**               | 與真實分類的相似度               |
| **降維（Dimensionality Reduction）**   | **Explained Variance Ratio（解釋變異比例）** | 主成分解釋的資訊量               |
|                                        | **Reconstruction Error（重建誤差）**         | 壓縮後還原的差異                 |
| **生成（Generative Models）**          | **FID（Fréchet Inception Distance）**        | 生成影像與真實影像的距離         |
|                                        | **IS（Inception Score）**                    | 生成影像的質量與多樣性           |
|                                        | **CLIP Score（CLIP 分數）**                  | 圖像與文字的匹配度               |
| **強化學習（Reinforcement Learning）** | **Cumulative Reward（累積獎勵）**            | 任務中的總得分                   |
|                                        | **Win Rate（勝率）**                         | 對戰任務贏的比例                 |
|                                        | **Convergence Speed（收斂速度）**            | 學到穩定策略的快慢               |

---

### 監督式學習步驟

| 步驟            | 說明                                   | 分類任務評估                                                                                                      | 回歸任務評估                                                                            |
| --------------- | -------------------------------------- | ----------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| **1. 資料準備** | 收集、清理、特徵工程、標籤化           | 同左                                                                                                              | 同左                                                                                    |
| **2. 資料分割** | 切成訓練集、測試集（可能有驗證集）     | 同左                                                                                                              | 同左                                                                                    |
| **3. 模型訓練** | 將訓練集輸入演算法，學習輸入與輸出關係 | 同左                                                                                                              | 同左                                                                                    |
| **4. 模型預測** | 用測試集進行預測，得到預測結果         | 同左                                                                                                              | 同左                                                                                    |
| **5. 模型評估** | 檢查模型在測試集的表現                 | **先計算混淆矩陣（TP/FP/FN/TN） → 再計算 Accuracy（準確率）、Precision（精確率）、Recall（召回率）、F1-score 等** | **直接計算 MSE（均方誤差）、RMSE（均方根誤差）、MAE（平均絕對誤差）、R²（決定係數）等** |
| **6. 模型優化** | 調整參數、特徵工程、模型選擇           | 同左                                                                                                              | 同左                                                                                    |
| **7. 部署**     | 將最優模型上線                         | 同左                                                                                                              | 同左                                                                                    |

---

#### **為什麼正則化可以避免過擬合？**

> 它會在訓練時「限制模型太複雜」，加懲罰讓模型不要去記訓練資料的雜訊，逼它學到更通用的規律。


**兩個常見方法**

| 方法            | 怎麼做                          | 好處           |
| --------------- | ------------------------------- | -------------- |
| **L1（Lasso）** | 懲罰權重的絕對值 → 有些權重變 0 | 幫你自動挑特徵 |
| **L2（Ridge）** | 懲罰權重的平方 → 全部權重變小   | 防止權重過大   |


**比喻**

> 沒正則化 = 你考試時把課本細節全背，連錯字都記下來（過擬合）<br>
> 有正則化 = 老師限制你只能用 50 字回答，逼你抓重點（泛化好）

---

設備異常訊號會**隨時間變化**，前一刻的狀態會影響下一刻，所以要用**時間序列模型**去抓趨勢和變化，這樣才能提早預測異常，而不是等異常發生才發現。

就像**看心電圖**，要看整條波形的走勢，不能只看某一個瞬間的數字。

---

| 階段            | POC                          | Prototype                | MVP                                    |
| --------------- | ---------------------------- | ------------------------ | -------------------------------------- |
| **全名 / 中文** | Proof of Concept（概念驗證） | Prototype（原型）        | Minimum Viable Product（最小可行產品） |
| **目的**        | 驗證技術或想法可不可行       | 展示功能與互動方式       | 推出最小版本讓用戶使用並收集回饋       |
| **完整度**      | 很低，只做核心概念           | 中等，有主要功能但不完整 | 高，可真實運作但功能少                 |
| **受眾**        | 內部團隊 / 技術決策者        | 團隊、客戶、投資人       | 真實用戶 / 市場                        |
| **時間成本**    | 幾天～幾週                   | 幾週～1 個月             | 幾週～幾個月                           |
| **範例**        | 簡單 AI 模型驗證精度         | 可互動的 UI 操作展示     | 核心功能的 APP 上架測試                |
| **記憶技巧**    | 可不可行？（技術驗證）       | 長什麼樣？（外觀與操作） | 能不能賣？（市場測試）                 |

---

| 工具                 | 操作方式                           | 擅長風格                     | 代表用途                    | 記憶技巧                |
| -------------------- | ---------------------------------- | ---------------------------- | --------------------------- | ----------------------- |
| **Midjourney**       | Discord 機器人指令                 | 藝術感、細節豐富、風格化強   | 插畫、概念設計、海報        | 🎨 藝術大師（風格美）    |
| **DALL·E**           | 網頁介面（ChatGPT 或 OpenAI 官網） | 寫實、乾淨、偏真實           | 寫實圖片、商業素材          | ✏️ 插圖小幫手（方便快）  |
| **Stable Diffusion** | 本地端或雲端部署（可自架）         | 可客製化模型，自由度最高     | 專案級影像生成、AI 藝術研究 | 🧪 開放實驗室（自由改）  |
| **RunwayML**         | 網頁平台（雲端運行）               | 影片生成與編輯、動態視覺特效 | 廣告影片、社群短片、動畫    | 🎥 AI 攝影棚（影片神器） |

---

### EU AI Act 的風險分類

| 等級        | 名稱         | 重點                         | 例子                                                                   | 規範                   |
| ----------- | ------------ | ---------------------------- | ---------------------------------------------------------------------- | ---------------------- |
| **第 1 級** | 不可接受風險 | 嚴重威脅人權、民主、安全     | - 社會信用評分系統<br>- 公共場所即時人臉辨識（除特例）<br>- 潛意識操控 | **全面禁止**           |
| **第 2 級** | 高風險       | 直接影響生命、權益、法律義務 | - 自駕車 AI 控制<br>- 醫療診斷 AI<br>- 招募與升遷決策 AI               | 嚴格合規檢查、人工監督 |
| **第 3 級** | 有限風險     | 可能誤導使用者決策           | - 聊天機器人<br>- 生成式 AI（圖片、文字）                              | 必須透明告知           |
| **第 4 級** | 最低風險     | 幾乎不影響安全               | - 遊戲 NPC<br>- 美顏濾鏡                                               | 自由使用，無需管制     |

---

#### **BERT vs GPT 的訓練方式**

| 項目           | BERT                                                                                               | GPT                                                               |
| -------------- | -------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |
| **全名**       | Bidirectional Encoder Representations from Transformers                                            | Generative Pre-trained Transformer                                |
| **架構**       | Transformer **Encoder**                                                                            | Transformer **Decoder**（自回歸）                                 |
| **讀取方向**   | 雙向（同時看左與右）                                                                               | 單向（從左到右）                                                  |
| **預訓練任務** | - **遮蔽語言模型（MLM）**：隨機遮住字詞，預測被遮的詞<br>- **下一句預測（NSP）**：判斷句子是否連續 | - **下一詞預測（Next Token Prediction）**：根據前文預測下一個字詞 |
| **資料來源**   | 大量未標註文本                                                                                     | 大量未標註文本                                                    |
| **學習方式**   | 自監督（從原句生成遮罩標籤）                                                                       | 自監督（從原句生成下一詞標籤）                                    |
| **微調方式**   | 加任務特定層，做分類、問答等                                                                       | 加任務特定層，或透過提示（prompt）直接生成                        |
| **典型應用**   | 文本分類、問答系統、語意相似度                                                                     | 文字生成、對話系統、摘要                                          |
| **訓練特性**   | 善於理解上下文                                                                                     | 善於生成連續文本                                                  |

📌 **記憶技巧**

* **BERT**：像老師「讀懂全文」再答題
* **GPT**：像小說家「一邊寫一邊想」

---

### ① 安全性（防止出事）

| 技術名稱                         | 中文解釋                 | 主要用途             | 應用範例                   |
| -------------------------------- | ------------------------ | -------------------- | -------------------------- |
| 對齊調整（Alignment）            | 讓模型符合人類價值與期望 | 避免有害回應         | ChatGPT 系統提示與對齊訓練 |
| 人類回饋強化學習（RLHF）         | 人工標註好壞回應再優化   | 降低偏見、提升安全性 | ChatGPT RLHF               |
| 紅隊測試（Red Teaming）          | 模擬惡意攻擊測試模型     | 找出安全漏洞         | 攻擊測試場景               |
| 內容過濾器（Content Filtering）  | 安全審查輸入/輸出        | 阻擋敏感內容         | 關鍵詞過濾                 |
| 差分隱私（Differential Privacy） | 在數據中加噪音           | 保護用戶隱私         | Apple 隱私保護             |
| 模型水印（Model Watermarking）   | 輸出加隱藏標記           | 偵測 AI 生成內容     | DeepMind 水印              |

---

### ② 品質提升（讓它更聰明）

| 技術名稱                                    | 中文解釋         | 主要用途         | 應用範例         |
| ------------------------------------------- | ---------------- | ---------------- | ---------------- |
| 微調（Fine-tuning）                         | 用特定資料再訓練 | 強化專業領域表現 | 醫療客服 LLM     |
| 檢索增強生成（RAG）                         | 查外部資料再生成 | 確保真實性       | 搜尋+生成        |
| 提示工程（Prompt Engineering）              | 精心設計提示詞   | 控制輸出風格     | 指定繁體中文回答 |
| 多步推理監控（Chain-of-Thought Monitoring） | 檢查推理過程     | 防止錯誤推論     | 逐步檢查邏輯     |
| 知識檢索與更新（Knowledge Refresh）         | 定期更新知識庫   | 避免過時資訊     | 新聞即時更新     |

---

### ③ 效能優化（跑得快又省）

| 技術名稱                           | 中文解釋           | 主要用途       | 應用範例         |
| ---------------------------------- | ------------------ | -------------- | ---------------- |
| 模型蒸餾（Knowledge Distillation） | 大模型教小模型     | 降低運算成本   | LLaMA → 小型 LLM |
| 主成分分析（PCA）                  | 壓縮特徵維度       | 減少計算量     | LLM 特徵壓縮     |
| 梯度提升決策樹（GBDT）             | 多顆決策樹逐步修正 | 精準分類與預測 | LLM 輸出後分類   |
| 集成學習（Ensemble Learning）      | 多模型投票/加權    | 提升穩定性     | 多 LLM 輸出加權  |

---

### ETL 資料處理流程

| 步驟          | 中文 | 做什麼                             | 例子                                 |
| ------------- | ---- | ---------------------------------- | ------------------------------------ |
| **Extract**   | 擷取 | 從不同資料來源抓資料               | 從 MySQL、CSV、API 抓取交易紀錄      |
| **Transform** | 轉換 | 清理、整合、格式化、計算           | 把日期轉成同一格式、計算每月交易總額 |
| **Load**      | 載入 | 將處理好的資料放入目標資料庫或倉儲 | 存到 Data Warehouse 供報表分析       |

---

